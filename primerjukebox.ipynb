{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"primer jukebox.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uq8uLwZCn0BV"},"source":["IMPORTANT NOTE ON SYSTEM REQUIREMENTS:\n","\n","Old text: [If you are connecting to a hosted runtime, make sure it has a P100 GPU (optionally run !nvidia-smi to confirm). Go to Edit>Notebook Settings to set this.\n","\n","CoLab may first assign you a lower memory machine if you are using a hosted runtime.  If so, the first time you try to load the 5B model, it will run out of memory, and then you'll be prompted to restart with more memory (then return to the top of this CoLab).  If you continue to have memory issues after this (or run into issues on your own home setup), switch to the 1B model.\n","\n","If you are using a local GPU, we recommend V100 or P100 with 16GB GPU memory for best performance. For GPUâ€™s with less memory, we recommend using the 1B model and a smaller batch size throughout.]  \n","\n","Edit: If you're a free Colab user, make sure you're assigned a T4 or P100 GPU. K80 will not work.\n","\n"]},{"cell_type":"code","metadata":{"id":"8qEqdj8u0gdN","cellView":"form"},"source":["#@title Connect!\n","!nvidia-smi -L"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VAMZK4GNA_PM"},"source":["Mount Google Drive to save sample levels as they are generated."]},{"cell_type":"code","metadata":{"id":"ZPdMgaH_BPGN","cellView":"form"},"source":["#@title Connect Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zy4Rehq9ZKv_"},"source":["Prepare the environment."]},{"cell_type":"code","metadata":{"id":"sAdFGF-bqVMY","cellView":"form"},"source":["#@title Prepare the enviroment\n","!pip install git+https://github.com/craftmine1000/jukebox-opt.git\n","###### autosave start\n","import os\n","from glob import glob\n","\n","filex = \"/usr/local/lib/python3.7/dist-packages/jukebox/sample.py\"\n","fin = open(filex, \"rt\")\n","data = fin.read()\n","fin.close()\n","\n","newtext = '''import fire\n","\n","from termcolor import colored\n","from datetime import datetime'''\n","data = data.replace('import fire',newtext)\n","\n","newtext = '''starts = get_starts(total_length, prior.n_ctx, hop_length)\n","        counterr = 0\n","        for start in starts:'''\n","data = data.replace('for start in get_starts(total_length, prior.n_ctx, hop_length):',newtext)\n","\n","newtext = '''counterr += 1\n","            datea = datetime.now()\t\t\n","            zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)\t\t\t\n","            dateb = datetime.now()\n","            timex = ((dateb-datea).total_seconds()/60.0)*(len(starts)-counterr)\n","            print(f\"Step \" + colored(counterr,'blue') + \"/\" + colored( len(starts),'red') + \" ~ estimated remaining minutes: \" + (colored('???','yellow'), colored(timex,'magenta'))[counterr >1])\n","            x = prior.decode(zs[level:], start_level=level, bs_chunks=zs[level].shape[0])\n","            logdir = f\"{hps.name}/level_{level}\"\n","            if not os.path.exists(logdir):\n","                os.makedirs(logdir)\n","            t.save(dict(zs=zs, labels=labels, sampling_kwargs=sampling_kwargs, x=x), f\"{logdir}/data.pth.tar\")\n","            save_wav(logdir, x, hps.sr)'''\n","data = data.replace('zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)',newtext)\n","\n","fin = open(filex, \"wt\")\n","fin.write(data)\n","fin.close()\n","###### autosave end\n","import jukebox\n","import torch as t\n","import librosa\n","import os\n","from IPython.display import Audio\n","from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n","from jukebox.hparams import Hyperparams, setup_hparams\n","from jukebox.sample import sample_single_window, _sample, \\\n","                           sample_partial_window, upsample, \\\n","                           load_prompts\n","from jukebox.utils.dist_utils import setup_dist_from_mpi\n","from jukebox.utils.torch_utils import empty_cache\n","rank, local_rank, device = setup_dist_from_mpi()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SZLTTUVdv4kL"},"source":["Customize the cell below if needed.\n","The current settings will generate one sample at 32000 Hz "]},{"cell_type":"code","metadata":{"id":"65aR2OZxmfzq"},"source":["model = '5b_lyrics' # or '5b' or '1b_lyrics'\n","hps = Hyperparams()\n","hps.sr = 32000\n","hps.n_samples = 1 if model in ('5b', '5b_lyrics') else 8\n","# We set this to the Google Drive mount point.\n","hps.name = '/content/gdrive/My Drive/samplestest444'# Don't Edit this cell!\n","chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n","max_batch_size = 2 if model in ('5b', '5b_lyrics') else 16\n","hps.levels = 3\n","hps.hop_fraction = [.5,.5,.125]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"VWC14iMqumYk"},"source":["#@title Do some more things\n","#@markdown **It'll prime off of the primer.wav file in your google drive**\n","vqvae, *priors = MODELS[model]\n","vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n","top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n","# Prime song creation using an arbitrary audio sample.\n","mode = 'primed'\n","codes_file=None\n","# Specify an audio file here.\n","audio_file = '/content/gdrive/My Drive/primer.wav'\n","# Specify how many seconds of audio to prime on.\n","prompt_length_in_seconds=6\n","sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JYKiwkzy0Iyf"},"source":["Specify your choice of artist, genre, lyrics, and length of musical sample. \n","\n","IMPORTANT: The sample length is crucial for how long your sample takes to generate. Generating a shorter sample takes less time. You are limited to 12 hours on the Google Colab free tier. A 50 second sample should be short enough to fully generate after 12 hours of processing. "]},{"cell_type":"code","metadata":{"id":"qD0qxQeLaTR0","cellView":"form"},"source":["#@title Set the sample seconds\n","sample_length_in_seconds = 36 #@param {type:\"slider\", min:36, max:120, step:1}          \n","                                       # Full length of musical sample to generate - we find songs in the 1 to 4 minute\n","                                       # range work well, with generation time proportional to sample length.  \n","                                       # This total length affects how quickly the model \n","                                       # progresses through lyrics (model also generates differently\n","                                       # depending on if it thinks it's in the beginning, middle, or end of sample)\n","hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n","assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OqWiP1wyyzLu"},"source":["Edit the metadata in the next cell, \n","[Use this link](https://github.com/openai/jukebox/tree/master/jukebox/data/ids) to view all the artists and genres. (This notebook uses v2)"]},{"cell_type":"code","metadata":{"id":"N6nCDV2PvTlw"},"source":["# Note: Metas can contain different prompts per sample.\n","# By default, all samples use the same prompt.\n","metas = [dict(artist = \"Unknown\",\n","            genre = \"Unknown\",\n","            total_length = hps.sample_length,\n","            offset = 0,\n","            lyrics = \"\"\"Tonight we dance around the flame\n","Then we get to play the spirit game\n","Spirit names we shout out loud\n","Shake the thunder from the spirit cloud\n","\"\"\",\n","            ),\n","          ] * hps.n_samples\n","labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNwKyqYraTR9","cellView":"form"},"source":["#@title Other Things\n","sampling_temperature = .98\n","\n","lower_batch_size = 16\n","max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n","lower_level_chunk_size = 32\n","chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n","sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n","                        chunk_size=lower_level_chunk_size),\n","                    dict(temp=0.99, fp16=True, max_batch_size=lower_batch_size,\n","                         chunk_size=lower_level_chunk_size),\n","                    dict(temp=sampling_temperature, fp16=True, \n","                         max_batch_size=max_batch_size, chunk_size=chunk_size)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6K7AayBDEiF-"},"source":["Level 2 is the completely raw audio. generate this one first."]},{"cell_type":"code","metadata":{"id":"9a1tlvcVlHhN","cellView":"form"},"source":["#@title Generate Raw Audio (Level 2)\n","if sample_hps.mode == 'ancestral':\n","  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cpu') for _ in range(len(priors))]\n","  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n","elif sample_hps.mode == 'upsample':\n","  assert sample_hps.codes_file is not None\n","  # Load codes.\n","  data = t.load(sample_hps.codes_file, map_location='cpu')\n","  zs = [z.cuda() for z in data['zs']]\n","  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n","  del data\n","  print('Falling through to the upsample step later in the notebook.')\n","elif sample_hps.mode == 'primed':\n","  assert sample_hps.audio_file is not None\n","  audio_files = sample_hps.audio_file.split(',')\n","  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n","  x = load_prompts(audio_files, duration, hps)\n","  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n","  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n","else:\n","  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eH_jUhGDprAt"},"source":["Please note: this next upsampling step will take several hours.  At the free tier, Google CoLab lets you run for 12 hours.  As the upsampling is completed, samples will appear in the Files tab (you can access this at the left of the CoLab), under \"samples\" (or whatever hps.name is currently).  Level 1 is the partially upsampled version, and then Level 0 is fully completed."]},{"cell_type":"code","metadata":{"id":"W5VLX0zRapIm","cellView":"form"},"source":["#@title Upsample Audio (Level 1 to 0)\n","# Set this False if you are on a local machine that has enough memory (this allows you to do the\n","# lyrics alignment visualization during the upsampling stage). For a hosted runtime, \n","# we'll need to go ahead and delete the top_prior if you are using the 5b_lyrics model.\n","if True:\n","  del top_prior\n","  empty_cache()\n","  top_prior=None\n","upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n","labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]\n","\n","zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3SJgBYJPri55"},"source":["Listen to your final samples!"]},{"cell_type":"code","metadata":{"id":"2ip2PPE0rgAb","cellView":"form"},"source":["#@title View Final Sample\n","del upsamplers\n","empty_cache()\n","Audio(f'{hps.name}/level_0/item_0.wav')\n"],"execution_count":null,"outputs":[]}]}